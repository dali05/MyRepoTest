package com.example.common.kafka;

import org.springframework.boot.context.properties.ConfigurationProperties;

import java.util.Map;

@ConfigurationProperties(prefix = "common.kafka")
public class KafkaAvroProperties {

    private boolean enabled = true;

    private BrokerProperties broker = new BrokerProperties();
    private SchemaRegistryProperties schemaRegistry = new SchemaRegistryProperties();

    private Map<String, String> producer;
    private Map<String, String> consumer;

    // Getters / Setters
    public boolean isEnabled() { return enabled; }
    public void setEnabled(boolean enabled) { this.enabled = enabled; }

    public BrokerProperties getBroker() { return broker; }
    public void setBroker(BrokerProperties broker) { this.broker = broker; }

    public SchemaRegistryProperties getSchemaRegistry() { return schemaRegistry; }
    public void setSchemaRegistry(SchemaRegistryProperties schemaRegistry) { this.schemaRegistry = schemaRegistry; }

    public Map<String, String> getProducer() { return producer; }
    public void setProducer(Map<String, String> producer) { this.producer = producer; }

    public Map<String, String> getConsumer() { return consumer; }
    public void setConsumer(Map<String, String> consumer) { this.consumer = consumer; }

    // Inner classes
    public static class BrokerProperties {
        private String bootstrapServers = "localhost:9092";
        public String getBootstrapServers() { return bootstrapServers; }
        public void setBootstrapServers(String bootstrapServers) { this.bootstrapServers = bootstrapServers; }
    }

    public static class SchemaRegistryProperties {
        private String url = "http://localhost:8081";
        public String getUrl() { return url; }
        public void setUrl(String url) { this.url = url; }
    }
}


package com.example.common.kafka;

import io.confluent.kafka.serializers.KafkaAvroDeserializer;
import io.confluent.kafka.serializers.KafkaAvroSerializer;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.common.serialization.StringSerializer;
import org.springframework.boot.autoconfigure.AutoConfiguration;
import org.springframework.boot.autoconfigure.condition.ConditionalOnClass;
import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;
import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;
import org.springframework.boot.context.properties.EnableConfigurationProperties;
import org.springframework.context.annotation.Bean;
import org.springframework.kafka.annotation.EnableKafka;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.core.*;

import java.util.HashMap;
import java.util.Map;

@AutoConfiguration
@EnableKafka
@EnableConfigurationProperties(KafkaAvroProperties.class)
@ConditionalOnProperty(prefix = "common.kafka", name = "enabled", havingValue = "true", matchIfMissing = true)
@ConditionalOnClass({KafkaTemplate.class, KafkaAvroSerializer.class})
public class KafkaAvroAutoConfiguration {

    @Bean
    @ConditionalOnMissingBean
    public ProducerFactory<String, Object> producerFactory(KafkaAvroProperties props) {
        Map<String, Object> config = new HashMap<>();
        config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, props.getBroker().getBootstrapServers());
        config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, KafkaAvroSerializer.class);
        config.put("schema.registry.url", props.getSchemaRegistry().getUrl());
        if (props.getProducer() != null) config.putAll(props.getProducer());
        return new DefaultKafkaProducerFactory<>(config);
    }

    @Bean
    @ConditionalOnMissingBean
    public KafkaTemplate<String, Object> kafkaTemplate(ProducerFactory<String, Object> pf) {
        return new KafkaTemplate<>(pf);
    }

    @Bean
    @ConditionalOnMissingBean
    public ConsumerFactory<String, Object> consumerFactory(KafkaAvroProperties props) {
        Map<String, Object> config = new HashMap<>();
        config.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, props.getBroker().getBootstrapServers());
        config.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        config.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, KafkaAvroDeserializer.class);
        config.put("schema.registry.url", props.getSchemaRegistry().getUrl());
        config.put("specific.avro.reader", "true");
        if (props.getConsumer() != null) config.putAll(props.getConsumer());
        return new DefaultKafkaConsumerFactory<>(config);
    }

    @Bean
    @ConditionalOnMissingBean
    public ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory(
            ConsumerFactory<String, Object> cf) {
        ConcurrentKafkaListenerContainerFactory<String, Object> factory =
                new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(cf);
        return factory;
    }
}



common:
  kafka:
    enabled: true
    broker:
      bootstrap-servers: localhost:9092
    schema-registry:
      url: http://localhost:8081
    producer:
      acks: all
    consumer:
      group-id: demo-group
      auto-offset-reset: earliest